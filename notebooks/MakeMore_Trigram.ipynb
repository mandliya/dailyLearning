{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVah5S0VOVoylqM8xcWf27",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mandliya/dailyLearning/blob/main/notebooks/MakeMore_Trigram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MakeMore Tri-Gram Model"
      ],
      "metadata": {
        "id": "bbjWLRsKX_oz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F4ftFlaSX-yi"
      },
      "outputs": [],
      "source": [
        "words = open('names.txt').read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VxqifupYQO_",
        "outputId": "141b7c37-3ab1-4007-e741-23d4db3246e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build char to index and index to char\n",
        "chars = ['.'] + sorted(list(set([c for word in words for c in word])))\n",
        "stoi = {c:i for i, c in enumerate(chars)}\n",
        "itos = {i:c for c, i in stoi.items()}"
      ],
      "metadata": {
        "id": "IRuBVuXpZmJf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build tri-gram count\n",
        "# use . as start and end token\n",
        "\n",
        "import torch\n",
        "\n",
        "N = torch.zeros((27, 27, 27), dtype=torch.int32)\n",
        "N.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNf9kS5qYZnq",
        "outputId": "670397e7-ff2a-478d-e19e-eec7442d31b4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([27, 27, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  chars = ['.'] + ['.'] + list(word) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chars, chars[1:], chars[2:]):\n",
        "    idx1, idx2, idx3 = stoi[ch1], stoi[ch2], stoi[ch3]\n",
        "    N[idx1, idx2, idx3] += 1"
      ],
      "metadata": {
        "id": "lhcLyaVxYuBa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First row\n",
        "N[0, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe5sZG8hZXt8",
        "outputId": "748849a0-b7e4-4ef0-e093-b3b3b532f043"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   0, 4410, 1306, 1542, 1690, 1532,  417,  669,  874,  591, 2422, 2963,\n",
              "        1572, 2538, 1146,  395,  515,   92, 1639, 2055, 1308,   78,  376,  307,\n",
              "         134,  535,  929], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert counts to probabilities for each pair of N gram\n",
        "\n",
        "P = N.float() + 1\n",
        "for i in range(27):\n",
        "  for j in range(27):\n",
        "    P[i, j] /= P[i, j].sum()"
      ],
      "metadata": {
        "id": "m-jIM9RZbRWm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P[0, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfhxwGP7gBNs",
        "outputId": "4af0705d-c99d-4cf7-b568-bf947dbe6ddc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.1190e-05, 1.3758e-01, 4.0765e-02, 4.8126e-02, 5.2742e-02, 4.7814e-02,\n",
              "        1.3037e-02, 2.0897e-02, 2.7291e-02, 1.8464e-02, 7.5572e-02, 9.2446e-02,\n",
              "        4.9061e-02, 7.9190e-02, 3.5774e-02, 1.2351e-02, 1.6094e-02, 2.9006e-03,\n",
              "        5.1151e-02, 6.4126e-02, 4.0827e-02, 2.4640e-03, 1.1758e-02, 9.6064e-03,\n",
              "        4.2106e-03, 1.6718e-02, 2.9006e-02])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P[0, 0].sum(), P[23, 24].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KncKllsngr2O",
        "outputId": "4b5ee722-4a72-4833-ffa7-04584b0dd784"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1.0000), tensor(1.))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "for i in range(10):\n",
        "  ix1, ix2 = 0, 0\n",
        "  w = []\n",
        "  while True:\n",
        "    ix2 = torch.multinomial(P[ix1, ix2], num_samples=1, replacement=True, generator=g).item()\n",
        "    if ix2 == 0:\n",
        "      break\n",
        "    w.append(itos[ix2])\n",
        "    ix1 = ix2\n",
        "  print(''.join(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53kIUexIg0M5",
        "outputId": "7bfe5313-af16-46b1-b723-eb94b79f3309"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "juwjde\n",
            "jphcqadhp\n",
            "cfaywadi\n",
            "a\n",
            "ji\n",
            "ritopemasareme\n",
            "sane\n",
            "aryanilenani\n",
            "dbyaine\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss calculation\n",
        "\n",
        "nll = 0\n",
        "n = 0\n",
        "for word in words:\n",
        "  chars = ['.'] + ['.'] + list(word) + ['.']\n",
        "  for c1, c2, c3 in zip(chars, chars[1:], chars[2:]):\n",
        "    idx1, idx2, idx3 = stoi[c1], stoi[c2], stoi[c3]\n",
        "    p = P[idx1, idx2, idx3]\n",
        "    logp = torch.log(p)\n",
        "    nll += logp\n",
        "    n += 1\n",
        "nll = -nll/n\n",
        "print(f'{nll=}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8FCvHAihvh3",
        "outputId": "7373cfb3-56f0-45f2-9f97-20e33a233019"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nll=tensor(2.2120)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lower than bi-gram model which was about 2.48.\n",
        "\n",
        "## Shallow Neural Network Model"
      ],
      "metadata": {
        "id": "7ybHShqMkqoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build an index of each bigram\n",
        "\n",
        "chars = ['.'] + sorted(list(set([c for word in words for c in word])))\n",
        "bigramIndex = {}\n",
        "i = 0\n",
        "for c1 in chars:\n",
        "  for c2 in chars:\n",
        "    bigramIndex[f'{c1}{c2}'] = i\n",
        "    i += 1 \n",
        "len(bigramIndex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYGuUPkTkqXO",
        "outputId": "c4b8ac9b-dec3-4988-ffad-8765c9b90a28"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "729"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#build dataset\n",
        "xs, ys = [], []\n",
        "for word in words:\n",
        "  chars = ['.'] + ['.'] + list(word) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chars, chars[1:], chars[2:]):\n",
        "    xs.append(bigramIndex[ch1 + ch2])\n",
        "    ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ],
      "metadata": {
        "id": "ChXv3aS9ka48"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs[1], ys[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6qKMdi3nip9",
        "outputId": "458a0020-bc2a-4068-b78e-30b96de9da1d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(5), tensor(13))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27*27, 27), generator=g, requires_grad=True)"
      ],
      "metadata": {
        "id": "mHiS60FVnsDk"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "xenc = F.one_hot(xs, num_classes=27*27).float()"
      ],
      "metadata": {
        "id": "iLSArxS2oaV5"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xenc.shape, W.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGWJVocJpGHk",
        "outputId": "ffbb1a6c-afdc-46e8-9227-e7ad0868b946"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([228146, 729]), torch.Size([729, 27]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = xs.nelement()\n",
        "num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1kXFRtmpVcU",
        "outputId": "000a83e5-93c4-476f-ecc5-19bfed943f03"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "228146"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for k in range(1000):\n",
        "  # Forward pass\n",
        "  logits = xenc @ W\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(dim=1, keepdims=True)\n",
        "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
        "  if k % 100 == 0:\n",
        "    print(f'iteration: {k}, loss: {loss.item()}')\n",
        "\n",
        "  # Backward Pass\n",
        "  W.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  W.data += -100 * W.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULyD7Fz2ozRZ",
        "outputId": "9feb2609-644c-48c9-854e-f137a52b1c61"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 0, loss: 3.8028223514556885\n",
            "iteration: 100, loss: 2.391273260116577\n",
            "iteration: 200, loss: 2.309091329574585\n",
            "iteration: 300, loss: 2.2774598598480225\n",
            "iteration: 400, loss: 2.2608020305633545\n",
            "iteration: 500, loss: 2.250521659851074\n",
            "iteration: 600, loss: 2.243560314178467\n",
            "iteration: 700, loss: 2.2385523319244385\n",
            "iteration: 800, loss: 2.2347869873046875\n",
            "iteration: 900, loss: 2.231858491897583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get some samples\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "for i in range(10):\n",
        "  ix1, ix2 = 0, 0\n",
        "  out = []\n",
        "  while True:\n",
        "    xenc = F.one_hot(torch.tensor([bigramIndex[itos[ix1] + itos[ix2]]]), num_classes = 27*27).float()\n",
        "    logits = xenc @ W\n",
        "    counts = logits.exp()\n",
        "    p = counts / counts.sum()\n",
        "    ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix2])\n",
        "    if ix2 == 0:\n",
        "      break\n",
        "    ix1 = ix2\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrM0O6Zips5C",
        "outputId": "cb358aad-19ea-4345-b0a1-35f698e4af28"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "junide.\n",
            "jpyaqadhu.\n",
            "cfaywadi.\n",
            "a.\n",
            "ji.\n",
            "ritopemasareme.\n",
            "sane.\n",
            "aryani.\n",
            "enani.\n",
            "dbyai.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFShs-FMsDOT",
        "outputId": "f4ebb0b9-596e-4377-b1c1-16dd7e493e2f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.2295, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final loss is almost same as the original count based model and the outputs too look almost similar!"
      ],
      "metadata": {
        "id": "XrpAzHRtvTug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "DBKqV7u8vSxM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}