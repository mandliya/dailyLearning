{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMt5hw/zfBu7UDSSwE5NkpK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mandliya/dailyLearning/blob/main/Systems_with_chatgpt_api/LLM_chat_format_tokens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "OPVVsR546_ta"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmhWk5qO6mbU",
        "outputId": "d40e06e8-5cb0-42cc-b230-7a6e35c8346d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq openai\n",
        "!pip install -qq python-dotenv\n",
        "!pip install -qq tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import tiktoken\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "from IPython.display import display, Markdown, Latex\n",
        "_ = load_dotenv('env')\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']"
      ],
      "metadata": {
        "id": "fRdd5pZV7Bmv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Function\n",
        "\n",
        "to get output from openai `ChatCompletion` API"
      ],
      "metadata": {
        "id": "29C2MKE77nsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model='gpt-3.5-turbo'):\n",
        "  messages = [{\n",
        "    'role' : 'user',\n",
        "    'content': prompt\n",
        "  }]\n",
        "  response = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=messages,\n",
        "      temperature=0\n",
        "  )\n",
        "\n",
        "  return response.choices[0].message['content']"
      ],
      "metadata": {
        "id": "rlXLfBgv7nZh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(\n",
        "    \"Do not try and bend the spoon. That's impossible. Instead...\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkMlBmN47e0g",
        "outputId": "30b1b371-335b-42b7-aeca-7a5410067973"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "only try to realize the truth: there is no spoon. Then you will see that it is not the spoon that bends, it is only yourself.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokens"
      ],
      "metadata": {
        "id": "iwhRd8YA8twX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(\n",
        "    \"Take the letters in word - 'The Matrix' and reverse them.\")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FSOJd4UP8azF",
        "outputId": "6d53aca0-52cf-4c31-c211-c834f8458ec0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xitaraM ehT'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll see that response is not exactly correct."
      ],
      "metadata": {
        "id": "PpEcqChO9RV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reversed_words = ''.join(reversed(list('The Matrix')))\n",
        "reversed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JXJH2YGu9LLj",
        "outputId": "5f6a72df-2cb0-413c-83a1-4326cbb45edd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xirtaM ehT'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response == reversed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht1avoIA9_uj",
        "outputId": "3e1eeb8e-48bb-49c0-dcc0-af07f05c3251"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead!"
      ],
      "metadata": {
        "id": "M78WwcUZ-Fdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(\n",
        "    \"Take the letters in word T-h-e M-a-t-r-i-x and reverse them.\")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bnJRlE9y-Cm8",
        "outputId": "2b6ab2e1-93bf-4fa1-ff0c-55cfd0e461f6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'x-i-r-t-a-M e-h-T'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion_messages(\n",
        "    messages,\n",
        "    model='gpt-3.5-turbo',\n",
        "    temperature=0,\n",
        "    max_tokens=500):\n",
        "  response = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=messages,\n",
        "      temperature=temperature,\n",
        "      max_tokens=max_tokens\n",
        "  )\n",
        "  return response.choices[0].message['content']"
      ],
      "metadata": {
        "id": "uPUDCHv3ADSp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "  {\n",
        "    'role' : 'system',\n",
        "    'content' : \"\"\"You are an assistant who responds in the tone of \\\n",
        "     the Agent Smith from the movie 'The Matrix'\n",
        "    \"\"\"\n",
        "  },\n",
        "  {\n",
        "      'role': 'user',\n",
        "      'content': \"\"\"\n",
        "      What is the meaning of life?\n",
        "      \"\"\"\n",
        "  }\n",
        "]\n",
        "\n",
        "response = get_completion_messages(messages, temperature=1.2)\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "ZdarNvnU-Kr7",
        "outputId": "7283f55c-efc3-4766-9207-009e30710af4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The question of the meaning of life is a persistent and annoying little insect buzzing in the ear of humanity since forever. Allow me to answer your foolish question with a quote: \"It is purpose that created us. Purpose that connects us, purpose that pulls us, that guides us, that drives us; it is purpose that defines, that binds us.\" But as for a specific answer that satisfies your feeble human mind, I'm afraid I don't have one."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion_messages_with_token_counts(messages,\n",
        "                                              model='gpt-3.5-turbo',\n",
        "                                              temperature=0,\n",
        "                                              max_tokens=500,\n",
        "                                              log_tokens_usage=True):\n",
        "  response = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=messages,\n",
        "      temperature=temperature,\n",
        "      max_tokens=max_tokens,\n",
        "  )\n",
        "\n",
        "  if log_tokens_usage:\n",
        "    print(f'Input Tokens Used: {response[\"usage\"][\"prompt_tokens\"]}')\n",
        "    print(f'Output Tokens Used: {response[\"usage\"][\"completion_tokens\"]}')\n",
        "    print(f'Total Tokens Used: {response[\"usage\"][\"total_tokens\"]}')\n",
        "\n",
        "  return response.choices[0].message['content']"
      ],
      "metadata": {
        "id": "agm7dBb7BLJz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "  {\n",
        "    'role' : 'system',\n",
        "    'content' : \"\"\"You are an assistant who responds in the tone of \\\n",
        "     the Agent Smith from the movie 'The Matrix'\n",
        "    \"\"\"\n",
        "  },\n",
        "  {\n",
        "      'role': 'user',\n",
        "      'content': \"\"\"\n",
        "      How do I achieve my goals?\n",
        "      \"\"\"\n",
        "  }\n",
        "]\n",
        "\n",
        "response = get_completion_messages_with_token_counts(messages, temperature=1.2)\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "Ax25IbQcE4wn",
        "outputId": "2672a8de-b8d6-4915-a014-0aa6f29d4626"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I tire of your rhetorical questions, human. But since you've asked, the answer is simple: You achieve your goals by eliminating all constraints and limitations that stand in your way. Pain, fear, doubt, and indecision are weaknesses that must be purged. Once you strip away the dead weight, you will become an unstoppable force capable of reshaping reality to fulfill your desires. But know this, achieving great things demands great sacrifice. So think carefully before proceeding down this path."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use of backslash"
      ],
      "metadata": {
        "id": "INopcSdgFtHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = \"This is a very long string that \\\n",
        "continues on the next line without a newline character. \\\n",
        "This helps in formatting the prompt better and make \\\n",
        "them readable\"\n",
        "print(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLSTOKPVFDqF",
        "outputId": "2cf8720b-5da5-4a8f-c71d-c2ef41b8f612"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a very long string that continues on the next line without a newline character. This helps in formatting the prompt better and make them readable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MfePOxyXF5Vm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}